# Source

[Securing AI Model Weights: Preventing Theft and Misuse of Frontier Models](https://github.com/olga-sorokoletova/Security-Mitigations/blob/main/Securing%20AI%20Model%20Weights/paper.pdf)

# Scope

**Objective:** Securing model assets.[^1]\
**Type of asset:** model weights.[^2]\
**Risks:** theft, copying, and mimicry.

[^1]: **Other AI Security concerns:** 1. Protecting AI system confidentiality, integrity, and availability; 2. Guarding against misuse of legitimate API; 3. Harm mitigations after the exfiltration; 4. Development of a robust R&D agenda to expand the AI security toolkit; 5. Researching the roles of different actors in securing AI systems.
[^2]: **Other assets subject to protection:** 1. Training data; 2. Algorithmic insights; 3. Model architecture design; 4. Operational infrastructure; 5. Source code.
